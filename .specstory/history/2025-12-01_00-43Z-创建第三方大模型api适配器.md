<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session ca1964a2-4808-4761-b276-9440f8b62997 (2025-12-01 00:43Z) -->

# 创建第三方大模型api适配器 (2025-12-01 00:43Z)

_**User (2025-12-01 00:43Z)**_

@SpringAIConfig.java (27-45) 假设有一个第三方大模型的api，不是标准的OpenAPI接口，需要通过rest调用，请帮我写适配器

---

_**Agent (model default, mode Agent)**_



---

查看相关代码结构，以便创建适配器。


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: src/main/java/com/pcagent/config/SpringAIConfig.java</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** • Searched codebase "ChatModelBuilder createIfAvailable implementation" • **15** results</summary>
            
| File | Lines |
|------|-------|
| `src/main/java/com/pcagent/util/ChatModelBuilder.java` | L24-89 |
| `src/main/java/com/pcagent/config/SpringAIConfig.java` | L47 |
| `src/main/java/com/pcagent/util/ChatModelBuilder.java` | L32 |
| `src/test/java/com/pcagent/service/LLMInvokerSysTest.java` | L10-49 |
| `src/test/java/com/pcagent/service/ProductConfigServiceTest.java` | L45 |
| `src/test/java/com/pcagent/service/ProductConfigService4CheckerTest.java` | L12-56 |
| `src/test/java/com/pcagent/service/PCAgentService4SessionSysTest.java` | L10-74 |
| `src/main/java/com/pcagent/util/ChatModelBuilder.java` | L79-94 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L36-76 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L67-111 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L105-147 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L142-189 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L45 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L215-261 |
| `src/test/java/com/pcagent/service/LLMInvokerSysTest.java` | L26 |

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** • Searched codebase "ChatModel interface implementation Spring AI" • **15** results</summary>
            
| File | Lines |
|------|-------|
| `src/main/java/com/pcagent/config/SpringAIConfig.java` | L47 |
| `src/main/java/com/pcagent/util/ChatModelBuilder.java` | L32 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L45 |
| `src/main/java/com/pcagent/util/ChatModelBuilder.java` | L24-89 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L142-189 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L36-76 |
| `src/main/resources/application.yml` | L41 |
| `src/test/java/com/pcagent/service/LLMInvokerTest.java` | L36 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L215-261 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L258-297 |
| `src/test/java/com/pcagent/service/LLMInvokerSysTest.java` | L26 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L67-111 |
| `src/test/java/com/pcagent/service/ProductConfigServiceTest.java` | L45 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L105-147 |
| `pom.xml` | L49-104 |

</details>
</tool-use>

---



---

查看 Spring AI 的 ChatModel 接口定义，了解需要实现的方法：


---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** • Grep for "import org\.springframework\.ai\.chat\.model\.ChatModel" in "src/main/java" • 3 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `src/main/java\com\pcagent\config\SpringAIConfig.java` | `import org.springframework.ai.chat.model.ChatModel;` | L5 |
| `src/main/java\com\pcagent\util\ChatModelBuilder.java` | `import org.springframework.ai.chat.model.ChatModel;` | L3 |
| `src/main/java\com\pcagent\service\LLMInvoker.java` | `import org.springframework.ai.chat.model.ChatModel;` | L11 |


</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** • Searched codebase "ChatModel call method implementation ChatResponse" • **15** results</summary>
            
| File | Lines |
|------|-------|
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L142-189 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L67-111 |
| `src/main/java/com/pcagent/util/ChatModelBuilder.java` | L24-89 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L185-222 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L45 |
| `src/main/java/com/pcagent/util/ChatModelBuilder.java` | L32 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L105-147 |
| `src/main/java/com/pcagent/config/SpringAIConfig.java` | L47 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L215-261 |
| `src/test/java/com/pcagent/service/LLMInvokerTest.java` | L170-218 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L295-330 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L258-297 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L36-76 |
| `src/main/java/com/pcagent/service/ProductConfigService.java` | L208-249 |
| `src/test/java/com/pcagent/service/LLMInvokerTest.java` | L36 |

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: src/main/java/com/pcagent/util/ChatModelBuilder.java</summary>

</details>
</tool-use>

---



---

检查项目依赖，确认可用的 HTTP 客户端：


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: pom.xml</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="generic" data-tool-name="list_dir">
<details>
            <summary>Tool use: **list_dir** • Listed directory undefined • **0** results</summary>
        
No results found
</details>
</tool-use>

---



---

创建自定义 ChatModel 适配器，用于调用第三方 REST API。先创建适配器类：


---

<tool-use data-tool-type="write" data-tool-name="write">

<details><summary>Tool use: **write** • Edit file: src/main/java/com/pcagent/util/CustomRestChatModel.java</summary>

**Chunk 1**
Lines added: 357, lines removed: 1

```diff
@@ -1,1 +1,357 @@
- 
+ package com.pcagent.util;
+ 
+ import com.fasterxml.jackson.databind.JsonNode;
+ import com.fasterxml.jackson.databind.ObjectMapper;
+ import lombok.extern.slf4j.Slf4j;
+ import org.springframework.ai.chat.model.ChatModel;
+ import org.springframework.ai.chat.model.ChatResponse;
+ import org.springframework.ai.chat.model.Generation;
+ import org.springframework.ai.chat.messages.AssistantMessage;
+ import org.springframework.ai.chat.messages.Message;
+ import org.springframework.ai.chat.prompt.Prompt;
+ import org.springframework.http.*;
+ import org.springframework.web.client.RestClientException;
+ import org.springframework.web.client.RestTemplate;
+ 
+ import java.util.HashMap;
+ import java.util.List;
+ import java.util.Map;
+ 
+ /**
+  * 自定义REST API ChatModel适配器
+  * 用于调用非标准OpenAPI接口的第三方大模型API
+  * 
+  * 配置说明：
+  * - CUSTOM_LLM_API_URL: 第三方API的完整URL（必需）
+  * - CUSTOM_LLM_API_KEY: API密钥（可选，根据实际需求）
+  * - CUSTOM_LLM_MODEL: 模型名称（可选）
+  * - CUSTOM_LLM_REQUEST_BODY_TEMPLATE: 请求体模板（可选，JSON格式）
+  * 
+  * 请求体模板支持以下占位符：
+  * - {messages}: 将被替换为消息列表
+  * - {prompt}: 将被替换为合并后的提示文本
+  * - {model}: 将被替换为模型名称
+  * - {temperature}: 将被替换为温度参数（默认0.7）
+  */
+ @Slf4j
+ public class CustomRestChatModel implements ChatModel {
+ 
+     private final String apiUrl;
+     private final String apiKey;
+     private final String model;
+     private final Double temperature;
+     private final String requestBodyTemplate;
+     private final RestTemplate restTemplate;
+     private final ObjectMapper objectMapper;
+ 
+     /**
+      * 构造函数
+      * 
+      * @param apiUrl API的完整URL
+      * @param apiKey API密钥（可为null）
+      * @param model 模型名称（可为null）
+      * @param temperature 温度参数（可为null，默认0.7）
+      * @param requestBodyTemplate 请求体模板（可为null，使用默认模板）
+      */
+     public CustomRestChatModel(String apiUrl, String apiKey, String model, 
+                                Double temperature, String requestBodyTemplate) {
+         if (apiUrl == null || apiUrl.isEmpty()) {
+             throw new IllegalArgumentException("API URL cannot be null or empty");
+         }
+         this.apiUrl = apiUrl;
+         this.apiKey = apiKey;
+         this.model = model;
+         this.temperature = temperature != null ? temperature : 0.7;
+         this.requestBodyTemplate = requestBodyTemplate;
+         this.restTemplate = new RestTemplate();
+         this.objectMapper = new ObjectMapper();
+     }
+ 
+     /**
+      * 从环境变量创建CustomRestChatModel实例
+      * 
+      * @return CustomRestChatModel实例，如果环境变量不可用则返回null
+      */
+     public static CustomRestChatModel createIfAvailable() {
+         String apiUrl = getEnvVar("CUSTOM_LLM_API_URL");
+         if (apiUrl == null || apiUrl.isEmpty()) {
+             return null;
+         }
+ 
+         String apiKey = getEnvVar("CUSTOM_LLM_API_KEY");
+         String model = getEnvVar("CUSTOM_LLM_MODEL");
+         String temperatureStr = getEnvVar("CUSTOM_LLM_TEMPERATURE");
+         Double temperature = temperatureStr != null ? Double.parseDouble(temperatureStr) : null;
+         String requestBodyTemplate = getEnvVar("CUSTOM_LLM_REQUEST_BODY_TEMPLATE");
+ 
+         try {
+             return new CustomRestChatModel(apiUrl, apiKey, model, temperature, requestBodyTemplate);
+         } catch (Exception e) {
+             log.error("Failed to create CustomRestChatModel: {}", e.getMessage(), e);
+             return null;
+         }
+     }
+ 
+     @Override
+     public ChatResponse call(Prompt prompt) {
+         try {
+             // 构建请求
+             HttpHeaders headers = buildHeaders();
+             String requestBody = buildRequestBody(prompt);
+             HttpEntity&lt;String&gt; entity = new HttpEntity&lt;&gt;(requestBody, headers);
+ 
+             log.debug("Calling custom LLM API: {}", apiUrl);
+             log.debug("Request body: {}", requestBody);
+ 
+             // 发送请求
+             ResponseEntity&lt;String&gt; response = restTemplate.exchange(
+                     apiUrl,
+                     HttpMethod.POST,
+                     entity,
+                     String.class
+             );
+ 
+             if (!response.getStatusCode().is2xxSuccessful()) {
+                 throw new RuntimeException("API call failed with status: " + response.getStatusCode());
+             }
+ 
+             String responseBody = response.getBody();
+             log.debug("API response: {}", responseBody);
+ 
+             // 解析响应
+             return parseResponse(responseBody);
+ 
+         } catch (RestClientException e) {
+             log.error("Failed to call custom LLM API", e);
+             throw new RuntimeException("Failed to call custom LLM API: " + e.getMessage(), e);
+         } catch (Exception e) {
+             log.error("Unexpected error while calling custom LLM API", e);
+             throw new RuntimeException("Unexpected error: " + e.getMessage(), e);
+         }
+     }
+ 
+     /**
+      * 构建HTTP请求头
+      */
+     private HttpHeaders buildHeaders() {
+         HttpHeaders headers = new HttpHeaders();
+         headers.setContentType(MediaType.APPLICATION_JSON);
+         
+         if (apiKey != null &amp;&amp; !apiKey.isEmpty()) {
+             // 根据实际API需求设置认证头
+             // 常见格式：Authorization: Bearer {apiKey} 或 X-API-Key: {apiKey}
+             // 这里默认使用Bearer格式，如果需要其他格式，可以通过环境变量配置
+             String authHeader = getEnvVar("CUSTOM_LLM_AUTH_HEADER", "Bearer");
+             if ("Bearer".equals(authHeader)) {
+                 headers.set("Authorization", "Bearer " + apiKey);
+             } else if ("X-API-Key".equals(authHeader)) {
+                 headers.set("X-API-Key", apiKey);
+             } else {
+                 // 自定义格式：CUSTOM_LLM_AUTH_HEADER=HeaderName:HeaderValue
+                 String[] parts = authHeader.split(":", 2);
+                 if (parts.length == 2) {
+                     headers.set(parts[0], parts[1].replace("{apiKey}", apiKey));
+                 } else {
+                     headers.set("Authorization", "Bearer " + apiKey);
+                 }
+             }
+         }
+ 
+         return headers;
+     }
+ 
+     /**
+      * 构建请求体
+      */
+     private String buildRequestBody(Prompt prompt) {
+         try {
+             // 合并所有消息为单个提示文本
+             String promptText = mergeMessages(prompt.getInstructions());
+ 
+             // 如果提供了自定义模板，使用模板
+             if (requestBodyTemplate != null &amp;&amp; !requestBodyTemplate.isEmpty()) {
+                 return buildRequestBodyFromTemplate(promptText);
+             }
+ 
+             // 否则使用默认模板
+             return buildDefaultRequestBody(promptText);
+ 
+         } catch (Exception e) {
+             log.error("Failed to build request body", e);
+             throw new RuntimeException("Failed to build request body: " + e.getMessage(), e);
+         }
+     }
+ 
+     /**
+      * 从模板构建请求体
+      */
+     private String buildRequestBodyFromTemplate(String promptText) {
+         String body = requestBodyTemplate;
+         
+         // 替换占位符
+         body = body.replace("{prompt}", escapeJson(promptText));
+         if (model != null) {
+             body = body.replace("{model}", escapeJson(model));
+         }
+         body = body.replace("{temperature}", String.valueOf(temperature));
+         
+         return body;
+     }
+ 
+     /**
+      * 构建默认请求体
+      */
+     private String buildDefaultRequestBody(String promptText) {
+         Map&lt;String, Object&gt; requestMap = new HashMap&lt;&gt;();
+         
+         if (model != null) {
+             requestMap.put("model", model);
+         }
+         
+         requestMap.put("prompt", promptText);
+         requestMap.put("temperature", temperature);
+         
+         try {
+             return objectMapper.writeValueAsString(requestMap);
+         } catch (Exception e) {
+             throw new RuntimeException("Failed to serialize request body", e);
+         }
+     }
+ 
+     /**
+      * 合并消息列表为单个文本
+      */
+     private String mergeMessages(List&lt;Message&gt; messages) {
+         StringBuilder sb = new StringBuilder();
+         for (Message message : messages) {
+             if (message.getContent() != null) {
+                 sb.append(message.getContent()).append("\n");
+             }
+         }
+         return sb.toString().trim();
+     }
+ 
+     /**
+      * 解析API响应为ChatResponse
+      */
+     private ChatResponse parseResponse(String responseBody) {
+         try {
+             JsonNode jsonNode = objectMapper.readTree(responseBody);
+             
+             // 尝试从常见字段中提取内容
+             String content = extractContent(jsonNode);
+             
+             if (content == null) {
+                 log.warn("Could not extract content from response, using raw response");
+                 content = responseBody;
+             }
+ 
+             // 创建AssistantMessage
+             AssistantMessage assistantMessage = new AssistantMessage(content);
+             
+             // 创建Generation
+             Generation generation = new Generation(assistantMessage);
+             
+             // 创建ChatResponse
+             return new ChatResponse(List.of(generation));
+ 
+         } catch (Exception e) {
+             log.error("Failed to parse API response", e);
+             // 如果解析失败，尝试将整个响应作为内容
+             AssistantMessage assistantMessage = new AssistantMessage(responseBody);
+             Generation generation = new Generation(assistantMessage);
+             return new ChatResponse(List.of(generation));
+         }
+     }
+ 
+     /**
+      * 从JSON响应中提取内容
+      * 支持常见的响应格式：
+      * - response.text
+      * - response.content
+      * - result.text
+      * - data.content
+      * - choices[0].message.content (OpenAI格式)
+      * - choices[0].text
+      */
+     private String extractContent(JsonNode jsonNode) {
+         // 尝试多种可能的字段路径
+         String[] paths = {
+             "response/text",
+             "response/content",
+             "result/text",
+             "result/content",
+             "data/content",
+             "data/text",
+             "content",
+             "text",
+             "message/content",
+             "message/text"
+         };
+ 
+         for (String path : paths) {
+             String content = getNestedValue(jsonNode, path);
+             if (content != null &amp;&amp; !content.isEmpty()) {
+                 return content;
+             }
+         }
+ 
+         // 尝试OpenAI格式：choices[0].message.content
+         if (jsonNode.has("choices") &amp;&amp; jsonNode.get("choices").isArray() 
+             &amp;&amp; jsonNode.get("choices").size() &gt; 0) {
+             JsonNode choice = jsonNode.get("choices").get(0);
+             if (choice.has("message") &amp;&amp; choice.get("message").has("content")) {
+                 return choice.get("message").get("content").asText();
+             }
+             if (choice.has("text")) {
+                 return choice.get("text").asText();
+             }
+         }
+ 
+         return null;
+     }
+ 
+     /**
+      * 获取嵌套JSON值
+      */
+     private String getNestedValue(JsonNode node, String path) {
+         String[] parts = path.split("/");
+         JsonNode current = node;
+         
+         for (String part : parts) {
+             if (current == null || !current.has(part)) {
+                 return null;
+             }
+             current = current.get(part);
+         }
+         
+         return current != null &amp;&amp; current.isTextual() ? current.asText() : null;
+     }
+ 
+     /**
+      * 转义JSON字符串
+      */
+     private String escapeJson(String str) {
+         return str.replace("\\", "\\\\")
+                   .replace("\"", "\\\"")
+                   .replace("\n", "\\n")
+                   .replace("\r", "\\r")
+                   .replace("\t", "\\t");
+     }
+ 
+     /**
+      * 获取环境变量
+      */
+     private static String getEnvVar(String key) {
+         return getEnvVar(key, null);
+     }
+ 
+     /**
+      * 获取环境变量（带默认值）
+      */
+     private static String getEnvVar(String key, String defaultValue) {
+         String value = System.getenv(key);
+         return value != null ? value : defaultValue;
+     }
+ }
+ 
```

</details>

</tool-use>

---



---

更新 `ChatModelBuilder`，支持创建自定义 REST ChatModel：


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: src/main/java/com/pcagent/util/ChatModelBuilder.java</summary>

</details>
</tool-use>

---



---

更新 `ChatModelBuilder`，添加对自定义 REST ChatModel 的支持：


---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** • Edit file: src/main/java/com/pcagent/util/ChatModelBuilder.java</summary>

**Chunk 1**
Lines added: 17, lines removed: 3

```diff
@@ -9,10 +9,24 @@
   * ChatModel 构建器
   * 用于根据环境变量创建 ChatModel 实例
-  * 支持 DeepSeek 和通义千问（Qinwen）
+  * 支持自定义REST API、DeepSeek 和通义千问（Qinwen）
   * 
-  * 注意：需要设置环境变量才能创建 ChatModel：
+  * 优先级顺序：
+  * 1. 自定义REST API（如果设置了 CUSTOM_LLM_API_URL）
+  * 2. DeepSeek（如果设置了 DEEPSEEK_API_KEY）
+  * 3. 通义千问（如果设置了 QINWEN_API_KEY）
+  * 
+  * 自定义REST API环境变量：
+  * - CUSTOM_LLM_API_URL: 第三方API的完整URL（必需）
+  * - CUSTOM_LLM_API_KEY: API密钥（可选）
+  * - CUSTOM_LLM_MODEL: 模型名称（可选）
+  * - CUSTOM_LLM_TEMPERATURE: 温度参数（可选，默认0.7）
+  * - CUSTOM_LLM_REQUEST_BODY_TEMPLATE: 请求体模板（可选，JSON格式）
+  * - CUSTOM_LLM_AUTH_HEADER: 认证头格式（可选，默认Bearer，支持：Bearer、X-API-Key或自定义格式）
+  * 
+  * DeepSeek环境变量：
   * - DEEPSEEK_API_KEY: DeepSeek API key
   * - DEEPSEEK_BASE_URL: DeepSeek API base URL (可选，默认: https://api.deepseek.com)
-  * 或
+  * 
+  * 通义千问环境变量：
   * - QINWEN_API_KEY: 通义千问 API key
   * - QINWEN_BASE_URL: 通义千问 API base URL (可选，默认: https://dashscope.aliyuncs.com/compatible-mode/v1)
```

</details>

</tool-use>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** • Edit file: src/main/java/com/pcagent/util/ChatModelBuilder.java</summary>

**Chunk 1**
Lines added: 8, lines removed: 2

```diff
@@ -41,10 +41,16 @@
      /**
       * 创建 ChatModel（如果环境变量可用）
-      * 优先尝试 DeepSeek，如果不可用则尝试通义千问
+      * 优先级：自定义REST API &gt; DeepSeek &gt; 通义千问
       * 
       * @return ChatModel 实例，如果环境变量不可用则返回 null
       */
      public static ChatModel createIfAvailable() {
-         // 优先尝试 DeepSeek
+         // 优先尝试自定义REST API
+         CustomRestChatModel customModel = CustomRestChatModel.createIfAvailable();
+         if (customModel != null) {
+             return customModel;
+         }
+ 
+         // 尝试 DeepSeek
          String deepseekApiKey = getEnvVar("DEEPSEEK_API_KEY");
          if (deepseekApiKey != null &amp;&amp; !deepseekApiKey.isEmpty()) {
```

</details>

</tool-use>

---



---

更新 `SpringAIConfig` 的注释，说明如何使用自定义 REST API 适配器：


---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** • Edit file: src/main/java/com/pcagent/config/SpringAIConfig.java</summary>

**Chunk 1**
Lines added: 17, lines removed: 6

```diff
@@ -17,10 +17,21 @@
   * 4. ProductConfigService 会自动注入 LLMInvoker（无论它是否有 ChatModel）
   * 
-  * 注意：需要设置环境变量才能创建 ChatModel：
-  * - DEEPSEEK_API_KEY: DeepSeek API key
-  * - DEEPSEEK_BASE_URL: DeepSeek API base URL (可选，默认: https://api.deepseek.com)
-  * 或
-  * - QINWEN_API_KEY: 通义千问 API key
-  * - QINWEN_BASE_URL: 通义千问 API base URL (可选，默认: https://dashscope.aliyuncs.com/compatible-mode/v1)
+  * 支持的ChatModel类型（按优先级）：
+  * 
+  * 1. 自定义REST API（CustomRestChatModel）：
+  *    - CUSTOM_LLM_API_URL: 第三方API的完整URL（必需）
+  *    - CUSTOM_LLM_API_KEY: API密钥（可选）
+  *    - CUSTOM_LLM_MODEL: 模型名称（可选）
+  *    - CUSTOM_LLM_TEMPERATURE: 温度参数（可选，默认0.7）
+  *    - CUSTOM_LLM_REQUEST_BODY_TEMPLATE: 请求体模板（可选，JSON格式，支持占位符：{prompt}, {model}, {temperature}）
+  *    - CUSTOM_LLM_AUTH_HEADER: 认证头格式（可选，默认Bearer，支持：Bearer、X-API-Key或自定义格式如"HeaderName:HeaderValue"）
+  * 
+  * 2. DeepSeek：
+  *    - DEEPSEEK_API_KEY: DeepSeek API key
+  *    - DEEPSEEK_BASE_URL: DeepSeek API base URL (可选，默认: https://api.deepseek.com)
+  * 
+  * 3. 通义千问（Qinwen）：
+  *    - QINWEN_API_KEY: 通义千问 API key
+  *    - QINWEN_BASE_URL: 通义千问 API base URL (可选，默认: https://dashscope.aliyuncs.com/compatible-mode/v1)
   */
  @Slf4j
```

</details>

</tool-use>

---



---

检查编译错误：


---

<tool-use data-tool-type="generic" data-tool-name="read_lints">
<details>
          <summary>Tool use: **read_lints** • Read lints for 2 files</summary>
      
Lint paths:

- `src/main/java/com/pcagent/util/CustomRestChatModel.java`
- `src/main/java/com/pcagent/util/ChatModelBuilder.java`

Lint results

Lint errors for `src/main/java/com/pcagent/util/CustomRestChatModel.java`


| Message | Range | Severity |
|-------|-------|----------|
| The type CustomRestChatModel must implement the inherited abstract method ChatModel.getDefaultOptions() | 37:14-37:33 | DIAGNOSTIC_SEVERITY_ERROR |


</details>
</tool-use>

---



---

需要实现 `getDefaultOptions()` 方法。检查 Spring AI 的 ChatModel 接口，确认需要实现的方法：


---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** • Searched codebase "ChatModel getDefaultOptions method implementation" • **15** results</summary>
            
| File | Lines |
|------|-------|
| `src/main/java/com/pcagent/util/ChatModelBuilder.java` | L5-82 |
| `src/main/java/com/pcagent/util/ChatModelBuilder.java` | L32 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L215-261 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L258-297 |
| `src/main/java/com/pcagent/util/ChatModelBuilder.java` | L79-98 |
| `src/main/java/com/pcagent/config/SpringAIConfig.java` | L49 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L36-76 |
| `src/main/java/com/pcagent/model/Parameter.java` | L23 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L45 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L67-111 |
| `src/main/resources/application.yml` | L41 |
| `src/test/java/com/pcagent/service/LLMInvokerTest.java` | L170-218 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L142-189 |
| `src/main/java/com/pcagent/service/ProductConfigService.java` | L430-479 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L105-147 |

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** • Grep for "getDefaultOptions" in "src/main/java" • 0 matches</summary>

Output mode: content


_No matches found_

</details>
</tool-use>

---



---

查看 Spring AI 的 ChatOptions 相关类，了解如何实现 `getDefaultOptions()`：


---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** • Searched codebase "ChatOptions interface Spring AI default options" • **15** results</summary>
            
| File | Lines |
|------|-------|
| `src/main/java/com/pcagent/util/ChatModelBuilder.java` | L5-82 |
| `src/main/java/com/pcagent/util/ChatModelBuilder.java` | L32 |
| `src/main/resources/application.yml` | L41 |
| `src/main/java/com/pcagent/config/SpringAIConfig.java` | L49 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L45 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L36-76 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L258-297 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L215-261 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L142-189 |
| `src/main/java/com/pcagent/service/ProductConfigService.java` | L430-479 |
| `src/main/java/com/pcagent/model/Parameter.java` | L23 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L67-111 |
| `frontend/src/App.vue` | L59-129 |
| `README.md` | L99 |
| `src/main/java/com/pcagent/service/LLMInvoker.java` | L351-393 |

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** • Grep for "ChatOptions|getDefaultOptions" in "src/main/java" • 9 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `src/main/java\com\pcagent\util\ChatModelBuilder.java` | `import org.springframework.ai.openai.OpenAiChatOptions;` | L5 |
| `src/main/java\com\pcagent\util\ChatModelBuilder.java` | `OpenAiChatOptions options = OpenAiChatOptions.builder()` | L83 |
| `src/main/java\com\pcagent\service\LLMInvoker.java` | `import org.springframework.ai.openai.OpenAiChatOptions;` | L18 |
| `src/main/java\com\pcagent\service\LLMInvoker.java` | `// 通过反射获取 OpenAiChatOptions` | L254 |
| `src/main/java\com\pcagent\service\LLMInvoker.java` | `OpenAiChatOptions options = (OpenAiChatOptions) optionsField.get(openAiChatModel);` | L257 |
| `src/main/java\com\pcagent\service\LLMInvoker.java` | `Method getModelMethod = OpenAiChatOptions.class.getMethod("getModel");` | L263 |
| `src/main/java\com\pcagent\service\LLMInvoker.java` | `Field modelField = OpenAiChatOptions.class.getDeclaredField("model");` | L267 |
| `src/main/java\com\pcagent\service\LLMInvoker.java` | `Method getTemperatureMethod = OpenAiChatOptions.class.getMethod("getTemperature");` | L280 |
| `src/main/java\com\pcagent\service\LLMInvoker.java` | `Field temperatureField = OpenAiChatOptions.class.getDeclaredField("temperature");` | L284 |


</details>
</tool-use>

---



---

添加 `getDefaultOptions()` 方法。先尝试返回 null，如果不行再创建实现：


---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** • Edit file: src/main/java/com/pcagent/util/CustomRestChatModel.java</summary>

**Chunk 1**
Lines added: 7, lines removed: undefined

```diff
@@ -92,4 +92,11 @@
          }
      }
+ 
+     @Override
+     public Object getDefaultOptions() {
+         // 返回null，因为自定义REST API不需要标准的ChatOptions
+         // 配置通过构造函数参数和环境变量管理
+         return null;
+     }
  
      @Override
```

</details>

</tool-use>

---



---

再次检查编译错误：


---

<tool-use data-tool-type="generic" data-tool-name="read_lints">
<details>
          <summary>Tool use: **read_lints** • Read lints for 1 file</summary>
      
Lint paths:

- `src/main/java/com/pcagent/util/CustomRestChatModel.java`

Lint results

Lint errors for `src/main/java/com/pcagent/util/CustomRestChatModel.java`


| Message | Range | Severity |
|-------|-------|----------|
| The return type is incompatible with ChatModel.getDefaultOptions() | 96:12-96:18 | DIAGNOSTIC_SEVERITY_ERROR |


</details>
</tool-use>

---



---

检查 `getDefaultOptions()` 的返回类型。查看 Spring AI 的相关接口：


---

<tool-use data-tool-type="search" data-tool-name="web_search">
<details>
            <summary>Tool use: **web_search** • Searched web `Spring AI ChatModel getDefaultOptions return type ChatOptions` • **1** results</summary>
        
| Title | URL | Chunk |
|-------|-----|-------|
| Web Search Results |  | 要在Spring Boot应用中调用非标准OpenAPI接口的第三方大模型API，您可以创建一个适配器类，使用`RestTemplate`或`WebClient`进行REST调用。以下是实现步骤：<br/><br/>1. **添加依赖项**：在`pom.xml`中添加`spring-boot-starter-web`依赖，以确保项目中包含必要的HTTP客户端工具。<br/><br/>   ```xml<br/>   <dependency><br/>       <groupId>org.springframework.boot</groupId><br/>       <artifactId>spring-boot-starter-web</artifactId><br/>   </dependency><br/>   ```<br/><br/><br/>2. **配置`RestTemplate`或`WebClient`**：在配置类中定义`RestTemplate`或`WebClient`的`Bean`，以供应用程序使用。<br/><br/>   ```java<br/>   @Configuration<br/>   public class AppConfig \{<br/><br/>       @Bean<br/>       public RestTemplate restTemplate() \{<br/>           return new RestTemplate();<br/>       \}<br/><br/>       @Bean<br/>       public WebClient webClient() \{<br/>           return WebClient.builder().build();<br/>       \}<br/>   \}<br/>   ```<br/><br/><br/>3. **创建适配器类**：编写一个适配器类，封装对第三方大模型API的调用逻辑。<br/><br/>   ```java<br/>   @Service<br/>   public class LargeModelApiAdapter \{<br/><br/>       private final RestTemplate restTemplate;<br/>       private final WebClient webClient;<br/><br/>       @Value("$\{thirdparty.api.url\}")<br/>       private String apiUrl;<br/><br/>       public LargeModelApiAdapter(RestTemplate restTemplate, WebClient webClient) \{<br/>           this.restTemplate = restTemplate;<br/>           this.webClient = webClient;<br/>       \}<br/><br/>       public String callApiWithRestTemplate(String input) \{<br/>           HttpHeaders headers = new HttpHeaders();<br/>           headers.setContentType(MediaType.APPLICATION_JSON);<br/>           HttpEntity<String> request = new HttpEntity<>(input, headers);<br/>           ResponseEntity<String> response = restTemplate.postForEntity(apiUrl, request, String.class);<br/>           return response.getBody();<br/>       \}<br/><br/>       public String callApiWithWebClient(String input) \{<br/>           return webClient.post()<br/>                   .uri(apiUrl)<br/>                   .contentType(MediaType.APPLICATION_JSON)<br/>                   .bodyValue(input)<br/>                   .retrieve()<br/>                   .bodyToMono(String.class)<br/>                   .block();<br/>       \}<br/>   \}<br/>   ```<br/><br/><br/>   在上述代码中，`callApiWithRestTemplate`方法使用`RestTemplate`进行同步调用，而`callApiWithWebClient`方法使用`WebClient`进行异步调用。<br/><br/>4. **配置API地址**：在`application.properties`或`application.yml`中添加第三方API的URL配置。<br/><br/>   ```properties<br/>   thirdparty.api.url=https://api.example.com/endpoint<br/>   ```<br/><br/><br/>5. **使用适配器**：在需要调用第三方大模型API的地方，注入并使用`LargeModelApiAdapter`。<br/><br/>   ```java<br/>   @RestController<br/>   @RequestMapping("/api")<br/>   public class ApiController \{<br/><br/>       private final LargeModelApiAdapter apiAdapter;<br/><br/>       public ApiController(LargeModelApiAdapter apiAdapter) \{<br/>           this.apiAdapter = apiAdapter;<br/>       \}<br/><br/>       @PostMapping("/process")<br/>       public ResponseEntity<String> process(@RequestBody String input) \{<br/>           String result = apiAdapter.callApiWithRestTemplate(input);<br/>           return ResponseEntity.ok(result);<br/>       \}<br/>   \}<br/>   ```<br/><br/><br/>通过上述步骤，您可以在Spring Boot应用中创建一个适配器，方便地调用非标准OpenAPI接口的第三方大模型API。 |

</details>
</tool-use>

---



---

尝试查找 Spring AI 中 ChatOptions 的定义。先查看项目中是否有相关导入：


---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** • Grep for "import.*ChatOptions|import.*chat\.options" in "src/main/java" • 2 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `src/main/java\com\pcagent\util\ChatModelBuilder.java` | `import org.springframework.ai.openai.OpenAiChatOptions;` | L5 |
| `src/main/java\com\pcagent\service\LLMInvoker.java` | `import org.springframework.ai.openai.OpenAiChatOptions;` | L18 |


</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: src/main/java/com/pcagent/util/CustomRestChatModel.java</summary>

</details>
</tool-use>

---



---

